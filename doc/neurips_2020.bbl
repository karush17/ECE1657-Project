\begin{thebibliography}{10}

\bibitem{atari}
Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis
  Antonoglou, Daan Wierstra, and Martin~A. Riedmiller.
\newblock Playing atari with deep reinforcement learning.
\newblock {\em CoRR}, abs/1312.5602, 2013.

\bibitem{go}
David Silver, Aja Huang, Chris~J. Maddison, Arthur Guez, Laurent Sifre, George
  van~den Driessche, Julian Schrittwieser, Ioannis Antonoglou, Veda
  Panneershelvam, Marc Lanctot, Sander Dieleman, Dominik Grewe, John Nham, Nal
  Kalchbrenner, Ilya Sutskever, Timothy Lillicrap, Madeleine Leach, Koray
  Kavukcuoglu, Thore Graepel, and Demis Hassabis.
\newblock Mastering the game of {Go} with deep neural networks and tree search.
\newblock {\em Nature}, 529(7587):484--489, January 2016.

\bibitem{shogi}
Julian Schrittwieser, Ioannis Antonoglou, Thomas Hubert, Karen Simonyan,
  Laurent Sifre, Simon Schmitt, Arthur Guez, Edward Lockhart, Demis Hassabis,
  Thore Graepel, Timothy Lillicrap, and David Silver.
\newblock Mastering atari, go, chess and shogi by planning with a learned
  model, 2019.

\bibitem{ddpg}
Timothy~P. Lillicrap, Jonathan~J. Hunt, Alexander Pritzel, Nicolas Manfred~Otto
  Heess, Tom Erez, Yuval Tassa, David Silver, and Daan Wierstra.
\newblock Continuous control with deep reinforcement learning.
\newblock {\em CoRR}, abs/1509.02971, 2015.

\bibitem{ppo}
John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov.
\newblock Proximal policy optimization algorithms.
\newblock {\em CoRR}, abs/1707.06347, 2017.

\bibitem{SC2}
Oriol Vinyals, Timo Ewalds, Sergey Bartunov, Petko Georgiev, Alexander~Sasha
  Vezhnevets, Michelle Yeo, Alireza Makhzani, Heinrich Küttler, John Agapiou,
  Julian Schrittwieser, John Quan, Stephen Gaffney, Stig Petersen, Karen
  Simonyan, Tom Schaul, Hado van Hasselt, David Silver, Timothy Lillicrap,
  Kevin Calderone, Paul Keet, Anthony Brunasso, David Lawrence, Anders Ekermo,
  Jacob Repp, and Rodney Tsing.
\newblock Starcraft ii: A new challenge for reinforcement learning, 2017.

\bibitem{maddpg}
Ryan Lowe, Yi~Wu, Aviv Tamar, Jean Harb, Pieter Abbeel, and Igor Mordatch.
\newblock Multi-agent actor-critic for mixed cooperative-competitive
  environments, 2017.

\bibitem{alphastar}
Oriol Vinyals, Igor Babuschkin, Wojciech Czarnecki, Michaël Mathieu, Andrew
  Dudzik, Junyoung Chung, David Choi, Richard Powell, Timo Ewalds, Petko
  Georgiev, Junhyuk Oh, Dan Horgan, Manuel Kroiss, Ivo Danihelka, Aja Huang,
  Laurent Sifre, Trevor Cai, John Agapiou, Max Jaderberg, and David Silver.
\newblock Grandmaster level in starcraft ii using multi-agent reinforcement
  learning.
\newblock {\em Nature}, 575, 11 2019.

\bibitem{cooperative}
Liviu Panait and Sean Luke.
\newblock Cooperative multi-agent learning: The state of the art.
\newblock {\em Autonomous agents and multi-agent systems}, 11(3):387--434,
  2005.

\bibitem{gt}
Ann Now{\'e}, Peter Vrancx, and Yann-Micha{\"e}l De~Hauwere.
\newblock Game theory and multi-agent reinforcement learning.
\newblock In {\em Reinforcement Learning}, pages 441--470. Springer, 2012.

\bibitem{selective}
Kaiqing Zhang, Zhuoran Yang, and Tamer Ba{\c{s}}ar.
\newblock Multi-agent reinforcement learning: A selective overview of theories
  and algorithms.
\newblock {\em arXiv preprint arXiv:1911.10635}, 2019.

\bibitem{smirl}
Glen Berseth, Daniel Geng, Coline Devin, Dinesh Jayaraman, Chelsea Finn, and
  Sergey Levine.
\newblock Smirl: Surprise minimizing rl in entropic environments.
\newblock 2019.

\bibitem{mbrl}
Lukasz Kaiser, Mohammad Babaeizadeh, Piotr Milos, Blazej Osinski, Roy~H
  Campbell, Konrad Czechowski, Dumitru Erhan, Chelsea Finn, Piotr Kozakowski,
  Sergey Levine, Afroz Mohiuddin, Ryan Sepassi, George Tucker, and Henryk
  Michalewski.
\newblock Model-based reinforcement learning for atari, 2019.

\bibitem{surprise}
Joshua Achiam and Shankar Sastry.
\newblock Surprise-based intrinsic motivation for deep reinforcement learning,
  2017.

\bibitem{surpmodeling}
Luis Macedo, Rainer Reisezein, and Amilcar Cardoso.
\newblock Modeling forms of surprise in artificial agents: empirical and
  theoretical study of surprise functions.
\newblock In {\em Proceedings of the Annual Meeting of the Cognitive Science
  Society}, volume~26, 2004.

\bibitem{gen}
Jerry~Zikun Chen.
\newblock Reinforcement learning generalization with surprise minimization,
  2020.

\bibitem{role}
Luis Macedo and Amilcar Cardoso.
\newblock The role of surprise, curiosity and hunger on exploration of unknown
  environments populated with entities.
\newblock In {\em 2005 portuguese conference on artificial intelligence}, 2005.

\end{thebibliography}
