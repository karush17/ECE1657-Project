# ECE1657 Project: Stochasitc Makrov Games for Multi-Agent Reinforcement Learning  

## Proposal (10 November)
- [ ] 1/2 Page  
- [ ] Should broadly highlight the research interest of Multi-Agent Learning and its growing need
- [ ] Describe the objective of the project (to explore the role of Stochastic Markov Games in MARL and various agent interactions)
- [ ] Briefly touch upon the algorithms and their differences (QMIX, VDN, COMA, IQL)
- [ ] Describe the environment setup (StarCraft II) and why is this suitable from a Game Theoretic perspective
- [ ] End up by laying out the outcomes expected (coordination must prevail, agent ineractions vary as per cost reduction, obtaining optimal strategies to defeat the enemy)

## Related Work
- [ ] Multi-Agent Reinforcement Learning: QMIX, VDN, COMA, IQL, Shimon Whiteson papers, Jakob Foerster thesis, etc. for algorithms
- [ ] Stochastic Games: MARL Review Papers, Reports, Surveys, etc. for Markov Games
- [ ] Should cover thorough background from Game Theoretic and RL perspective
- [ ] StarCraft II: Emphasize on the application area and its relation to real world on the basis of coordination

## Background
- [ ] Stochastic Markov Games: Focus should be on Stochastic Markov Games and their analytical description
- [ ] Multi-Agent Learning: Description should cover introduction, notation, background and expressions
- [ ] Each term should be explained clearly and concisely
- [ ] Nash Equilibrium, Optimal Responses and other important results must be highlighted

## Learning in Stochastic Games
- [ ] Partial Observability: Decribe and walk the reader through the partial observability setting
- [ ] Explain analytically and intuitively how agents tackle this problem
- [ ] Collaborative Agents: Explain each algorithm in detail and how it entaisl to collaboration between different agents (4 sections- IQL, COMA, VDN, QMIX)
- [ ] Note that the emphasis in this section should be mostly on algorithms and their functioning from Game Theoretic perspective

## 

